# The Thinking Machine

**Author:** Stephen Witt
**Description:** undefined
**Duration:** undefined min | **Rating:** [object Object]/5

---

## INTRODUCTION: What’s in it for me? Find out how a graphics chip held the secret to today’s entire technological landscape.

If you were deep into playing Half-Life 2 or Counter-Strike in the early 2000s, you probably knew all about Nvidia. Back then, Nvidia’s graphic processor chips, known as GPUs, were all the rage and obsessive gamers loved to show them off in custom see-through rigs with glowing cases. But few people knew that the advancements Nvidia had made in its gaming chips had actually unlocked the processing power needed for things like machine learning, which would in turn make innovations like Chat-GPT possible. This happened in large part because of Jensen Huang, the head of Nvidia, who kept pushing his company into the field of academic research even when it was far from profitable. In this Blink, we’ll look at the remarkable life of Jensen Huang and the story of how Nvidia went from niche products to powering most of today’s technology.

---

## CHAPTER 1 OF 8: A new Kentucky home

The year was 1973, and Jensen Huang was far from home. Born in Taiwan, and raised in Thailand, Jensen was ten years old and waking up in a drafty dorm room in rural Kentucky. His parents had sent him to America to escape political unrest and, through a twist of fate, he ended up at a small, rough-around-the-edges boarding school called the Oneida Baptist Institute. Chances are, his father thought it was an elite private school, when in reality it was more like a reform school. Being the only Asian kid in a sea of white classmates, Jensen stuck out. To make matters worse, while his English wasn’t great, he immediately proved himself to be one of the smartest kids in school. This made him an easy target for bullies. But Huang wasn’t a pushover. He pretended to be a martial arts expert and if someone forced him into a fight, he’d be the last one to back down or give up. His classmates quickly learned that Huang had grit. So, being stuck in the middle of rural Kentucky didn’t bother him. He saw it as a challenge – one that only helped to nurture his preternatural self-confidence and determination. In 1976, when it came time for high school, his father had finally found work in the US and the family was reunited in Oregon. This is when, in the suburbs of Portland, Huang found his people – fellow math and science nerds, and the misfits of the local computer club. He dove headfirst into the new Apple II computer, fell in love with coding, and found a surprising second passion in table tennis. Like everything else, he gave ping-pong everything he had, and within a year, he was nationally ranked. Around this time is when Huang picked up a job as a busboy at a local Denny’s. Meanwhile, he aced his classes and decided to ignore the lure of the Ivy Leagues and enroll at Oregon State University instead. It was kismet, as during the very first week of classes he met his future wife, Lori Mills. They were assigned as lab partners and the two bonded over homework. Huang considered doing homework his “superpower,” and Lori was apparently impressed. When he graduated with honors, microchips were starting to take over the world. His timing couldn’t have been better. Skilled circuit designers were suddenly the rock stars of the new tech era, and Huang was ready to join them in Silicon Valley.

---

## CHAPTER 2 OF 8: The trio’s first chip

By the time Huang proposed to Mills, he was already making a name for himself in Silicon Valley. It was the mid-80s, and 20-year-old Huang was working for Advanced Micro Devices, better known as AMD, one of the Valley’s most influential chipmakers. He still remembers his starting salary – $28,700 – not just as a number, but as a sign of how far he would come. Huang’s early days at AMD were a hands-on crash course in chip design, but he soon moved on to LSI Logic, where his intensity and work ethic quickly set him apart. This is where Huang came to know two important figures in his life: Curtis Priem and Chris Malachowsky. They were engineers who worked at Sun Microsystems, a demanding client of LSI Logic. Priem was a circuit-savant who could fall into a trance-like state as architectural schematics floated around in his mind. Malachowsky was the builder, the more practical and hands-on of the two. And when the three came together Huang was like the bridge who could bring their ideas to reality. He was a master at organizing production and pushing designs through to mass manufacturing. The trio clicked – each man excelling in his own lane. In 1989, the trio debuted their first product, the Sun GX, a graphics processor that could transform wire-frame skeletons into pixelated 3D shapes. By today’s standards, it’s primitive. But at the time, it was nothing short of revolutionary. It immediately put Huang on everyone’s radar, and LSI’s founder, Wilf Corrigan, promoted him to lead a new system-on-a-chip platform. The graphics chip got Priem and Malachowsky thinking: maybe there’s a market for a cheaper version that could be aimed directly at gamers. When Sun passed on the idea, it was one of those rejections that set the wheels of fortune into motion. Priem and Malachowsky took the idea to Huang, along with a bold proposal: leave LSI, and head up their new company. It wasn’t an easy decision. By then, Huang and Mills were married with two young kids. And he knew how brutal the hardware world could be – most start-ups didn’t even make it to market. Before he could make a decision, the three men would have to hash things out at Denny’s.

---

## CHAPTER 3 OF 8: The NV1 goes bust

Part of the business plan made perfect sense. In the early ’90s, there was a growing consumer video game market that the big players like Sun Microsystems and Silicon Graphics were choosing to ignore. But it was also true that a whole stampede of startups were rushing to fill in this gap – to turn high-end graphics tech into something PC gamers could use. The key invention was the “graphics accelerator” – a plug-in circuit board with a graphics chip at its heart. For Huang, this was an attractive challenge, and after a few meetings with Priem and Malachowsky in the back of the local Denny’s, tinkering with projections, he talked himself into the risk. There was, however, a personal benchmark: if they couldn’t clear $50 million in yearly revenue, it wasn’t going to be worth his time. Their new company didn’t even have a name at first – just “NV” for “new venture.” But this soon became Nvidia, inspired by the Latin word for “envy”, invidia. To stand out, they packed their first chip – the NV1 – with cutting-edge tech in the form of quadratic texture mapping. It succeeded in catching the attention of investors, and when the NV1 finally launched in 1995, for one hot second, it felt like they were hot stuff. PC gaming was exploding thanks to titles like Myst and Doom, and Nvidia sold over 100,000 chips, thanks in part to being bundled with Virtua Fighter. But then the rug was pulled out from under them. Most developers were using triangles to build 3D graphics, not the fancy quadratic approach the NV1 was pushing. So when Microsoft announced its new DirectX standard – which only supported triangles – Nvidia’s shiny new chip was instantly outdated. Nvidia would need to either successfully reboot in record time or join the countless other hardware companies in Silicon Valley’s startup graveyard.

---

## CHAPTER 4 OF 8: The risk pays off

The mood at Nvidia in 1996? “Funereal” would be a nice way of putting it. When Huang was done cleaning house, all that was left was a skeleton crew of 35 engineers. Their survival was based on coming up with a last-ditch graphics card – and fast. The NV1 disaster was the first time people got a taste of Huang’s leadership style. In a word, it’s explosive. And public. Huang doesn’t scream at you behind closed doors, he does it at meetings and in the open so that everyone gets the message. Even Priem was not safe from Huang’s wrath. But this moment in Nvidia history would also showcase the bright side of Huang’s leadership skills. With no time or money for prototypes, he decided they’d go straight to production using an emulator – essentially programming a fake version of the new microchip that would allow them to test their work. But it was risky. The emulator was entirely code-based, and if one line was off it could spell another disaster. They were setting up a scenario where they would get their demo chip back from the manufacturers in Taiwan and it would either work, and they would live another day, or it wouldn’t, and they were dead in the water. Miraculously, it worked. They named it the Riva 128. It ran at 30 frames per second and was a hit with gamers everywhere – it sold like crazy. Nvidia quickly leveled up when John Carmack, the gaming wizard behind Quake, picked Nvidia as the company to build a faster chip to meet his 3D graphics needs. Nvidia delivered the Riva TNT. It was the first to successfully crack the parallel computing challenge, allowing for twin pixel shading pipelines – doubling the chip’s capabilities of rendering more realistic graphics. Carmack called it “the perfect card.” By 1998, Nvidia was taking over gaming. But unknown to anyone at the time, at the core of the TNT chip was something much bigger.

---

## CHAPTER 5 OF 8: Parallel successes

In the late ’90s, all Nvidia was trying to do was make the best graphics cards on the market. And by committing itself to coming out with updates every six months, it was, to put it bluntly, kicking ass. But in cracking the parallel computing hurdle, it unwittingly created a product for a whole new demographic: scientists. Since the 1970s, researchers had been trying to create a neural net – a version of artificial intelligence inspired by the structure of the human brain. Many in the field thought neural nets were a waste of time, but in 1986, the tide turned. David Rumelhart, Geoffrey Hinton, and Ronald Williams unveiled the backpropagation algorithm – a way for neural nets to learn from their successes and mistakes and make adjustments, just like a real brain. At IBM, Gerald Tesauro took a neural net and taught it backgammon by letting the program play itself millions of times. The result was TD-Gammon, which became so good at inventing new strategies that even human pros were amazed. What was becoming clear was that the more data you could process, the better the result. And for that, Nvidia’s parallel computing GPUs were just the thing. Nvidia released its first GPU in 1999. But don’t be fooled, GPU, or graphics-processing unit, was just a marketing term Nvidia invented to promote their newest graphics accelerator, the GeForce. It was a huge hit with gamers. The GeForce line powered the golden age of PC gaming in the early 2000s, with titles like Half-Life 2, World of Warcraft, and Call of Duty. But word was getting out that those same GPUs, designed to render headshots and explosions, had another use. Ian Buck, a Stanford grad student was part of a crew of researchers behind Brook, a programming language that let scientists hijack Nvidia chips to crunch huge numbers for things like galaxy formation and nuclear simulations. Huang immediately brought Buck on board at Nvidia. He, along with Nvidia engineer John Nickolls, were part of a project known as CUDA or Compute Unified Domain Architecture. Released in 2006, CUDA was like Nvidia’s secret weapon, a way of turning a gaming chip – or multiple gaming chips – into a scientific supercomputer. It was a niche market, but soon scientists, researchers, even hospitals started buying up GeForce cards. For years the CUDA project was a money-loser. But gamers were footing the bill and Huang never had any doubts. He was building the future of computing and happy to let teenagers playing Counter-Strike pay for it.

---

## CHAPTER 6 OF 8: Huang’s investment pays off

While most of the world shrugged at what CUDA was capable of, Huang was hiring academic legends like Bill Dally to turn Nvidia Research into a world-class R&amp;D engine. But Geoffrey Hinton’s AI group in Toronto was aware of CUDA’s power. Among his group was a quiet genius named Alex Krizhevsky who used CUDA and some Nvidia GPUs to build a neural network that could recognize images faster and better than anything that came before. The model was called AlexNet. The machine learning revolution had begun and Huang’s decade of persistence was about to start paying off. The engineer Bryan Catanzaro joined Nvidia in 2011 and built cuDNN, a tool that made training neural networks on Nvidia’s GPU platform way faster. Huang called cuDNN the most important project in the company’s 20-year history. On his whiteboard he wrote the letters: “O.I.A.L.O.” – Once in a Lifetime Opportunity. In early 2014, Catanzaro demoed cuDNN live, using it to identify dog breeds on Twitter in real time. It was charming, it was powerful, it was just the beginning. Major players like Facebook, Adobe, and Netflix were paying attention – and secretly, so was Google. Google bought the AI startup DeepMind and was now scooping up Nvidia GPUs like candy for “Project Mack Truck,” a massive AI supercomputer. At last, Wall Street was finally looking at Nvidia as not just a gaming company but the growing backbone of the AI revolution. As a result, in 2016, Nvidia’s stock skyrocketed 224 percent and put Huang back on the billionaire list. But he kept pushing and putting targets on rivals like his old employer AMD. So it was that 2017 was the year of domination. Revenues doubled, profits tripled, and product launches flew out left and right. Nvidia’s GPUs were now powering Nobel Prize-winning science, making Amazon and Microsoft’s cloud computing possible, and being used to mine cryptocurrency, which was a whole other gold rush that helped push Nvidia to its first billion-dollar profit year. Meanwhile, CUDA downloads were through the roof as students and startups raced to build the next big AI breakthrough. This happened when Jakob Uszkoreit and a few other researchers at Google built a product that didn’t just beat Google Translate – it ate its lunch. Their advancement was made possible by the transformer. The transformer did things differently by being fed buckets of data and then predicting one word at a time. And doing this, it picked up deep, unspoken rules of language – like adjective order or pronoun clarity – without anyone teaching it. And it wasn’t just words. The transformer could compose music, paint, even “understand” art. It was like a skeleton key for creativity. The irony of this discovery is that Google didn’t really care. So Uszkoreit and the rest of the team quit and took their knowledge to other startups. One of them landed at OpenAI, where the tech became the backbone of something new: the Generative Pre-Trained Transformer, or GPT.

---

## CHAPTER 7 OF 8: Good news and bad news

The real judgment day arrived on February 21, 2024, the day of Nvidia’s earnings call. Over the past few years, Nvidia had expanded with the $7 billion purchase of the Israeli data center and networking company Mellanox, and it had signed a $100 million deal with OpenAI to train GPT-4. It now controlled 90 percent of the AI chip market, and its chips were seeing gross profit margins of over 90 percent. No one was harnessing raw computational power like Nvidia. But the earnings call would tell the true story. Beginning just after the stock market closed, it was one of the most listened-to earnings reports in Wall Street history. Colette Kress, Nvidia’s CFO, opened with the news: annual revenues had more than doubled to $60 billion, and the company had an impressive 70 percent gross margin – beating even Apple. The net income was almost $30 billion, more than Nvidia had earned in the past 30 years combined. To put it another way: every employee at Nvidia was now generating a million bucks in profit. The next day, Nvidia’s market value shot up by $277 billion – more than Coca-Cola’s entire worth. Nvidia now joined Microsoft and Apple as one of the three most valuable companies on Earth. But how stable is Nvidia’s position? Sure, Huang is on top of the world now. But he’s also all alone. There’s no one by his side. No successor, no second-in-command. Nvidia’s leadership structure is lean, and Huang himself has become irreplaceable. Is betting on Nvidia basically like betting on the power of a single individual to lead the way? The international situation is just as precarious. The biggest question being Nvidia’s longstanding relationship with Taiwan, the center of chip manufacturing. With China’s increasingly aggressive stance toward Taiwan, the nation’s chip plants – particularly TSMC, which has been invaluable in being the one manufacturer that can handle Nvidia’s high demands – are a critical point of vulnerability. The slightest disruption could trigger a massive crisis, sending shockwaves through the global economy. Some believe that the US would never allow China to take control of TSMC – but that belief requires a good amount of faith.

---

## CHAPTER 8 OF 8: Future threats or endless hope?

The last thing to consider is the future of AI itself. Is the current progress really sustainable? Putting aside questions of whether AI could become self-aware and threaten humanity, there are already some very real threats to Earth to consider. Nvidia’s rise sparked a huge increase in global electricity demand. Companies like Google and Microsoft are seeing emissions skyrocket due to their ever-expanding data centers. Nvidia’s chips, powering most of them, are massive consumers of electricity. Just a few years ago, their DGX boxes used about the same power as a clothes dryer. Today’s systems are sucking up enough electricity to power entire homes. That said, many people including big names in the field such as Geoffrey Hinton, have genuine fear about the threat AI poses to humanity. Huang doesn’t. In an interview with the author Stephen Witt, Huang unleashed one of his famous outbursts, yelling at him about the pointlessness of such fears, calling them unserious, sci-fi nonsense. None of this did anything to quiet Witt’s own misgivings. He left the interview with a feeling that Huang didn’t consider human extinction as a valid factor in his corporate strategy, and so it didn’t matter. And Nvidia’s other executives were likely too afraid of being screamed at by Huang to challenge his point of view. The scope of Nvidia’s accomplishments are so immense it’s hard to grasp, even when you’re standing in one of the company’s computing pods, with the fans blowing so loudly you can’t hear yourself think. So it remains an open question: Will it be a utopia, or will we lose control entirely? Maybe Huang is the only one who can see it all clearly.

---

## CONCLUSION: Final summary

In this Blink to The Thinking Machine by Stephen Witt, you’ve learned that the story of Nvidia’s success is also the story of Jensen Huang, an immigrant who came to the US as a self-determined ten-year-old. A gifted student, he embraced computer technology in the early 1980s and quickly found a job in the Silicon Valley. Alongside Curtis Priem and Chris Malachowsky he started Nvidia and produced groundbreaking graphics chips for the PC gaming boom of the early 2000s. Those chips also contained the seeds of the machine learning and AI revolution, as well as powering cloud computing and cryptocurrency mining. Nvidia has since gone on to become one of the most successful companies, surpassing Apple in value. While the future of AI and Nvidia remain uncertain,Huang continues to push the company forward into uncharted territory. Okay, that’s it for this Blink. We hope you enjoyed it. If you can, please take the time to leave us a rating – we always appreciate your feedback. See you in the next Blink.
