# Impromptu

**Author:** Reid Hoffman with GPT-4
**Description:** Amplifying Our Humanity Through AI
**Duration:** 16 min | **Rating:** 4.1/5

---

## INTRODUCTION: What’s in it for me? Catch a glimpse of a fascinating and hopeful future.

How many restaurant inspectors does it take to change a light bulb? Pose this question to GPT-4 – the state-of-the-art Artificial Intelligence developed by OpenAI – and it may offer two answers. A factual answer: One inspector should be enough, as long as they follow proper safety procedures. Or a joke answer: Four – one to hold the ladder, one to unscrew the bulb, another to screw in the new one, and a fourth to write up a citation for incorrect wattage. Not bad for a computer – and the fact that it thought to offer two answers is even more impressive. It gets better. Ask for that same joke in the style of Jerry Seinfield and GPT-4 will go into an original, grammatically correct and tonally accurate monologue that could easily have been delivered by the comedian, starting with, “What’s the deal with restaurant inspectors?” Ask for the style of philosopher Ludwig Wittgenstein and you’ll get a convincing speech on the nature of language and the abstract purpose of restaurant inspectors. Pretty entertaining. But it can do more than generate novel responses to clichéd jokes. GPT-4 is what’s known as a Large Language Model, or LLM – it draws from vast databases of natural writing and information to create believable responses from just a few prompts. Poetry, prose, facts, speculation – it can do it all, if asked. Take a moment to consider how this could be used in fields like education, justice, or journalism, for example. This Blink is a discussion about those possibilities – call it a travelog for the future – with input, suggestions, and speculation from GPT-4 itself. That’s right – many of the ideas you are about to hear are not just those of the author, but the answers he received by asking the AI for its opinion. With that in mind, let's take a look at what the future holds.

---

## CHAPTER 1 OF 5: AI and Education

Mention the idea of AI entering the world of education and academia, and people respond with outrage: “Students will be able to find all the answers!” “It’ll be easier to cheat!” However, when beloved seventy-year-old professor Stephen Mintz was introduced to ChatGPT – a publicly available chat application that is based on GPT-4 – he had a different reaction. He couldn’t wait to start incorporating it into his lessons. New technology has often changed the face of education: Calculators allowed for more complex math problems. Google made us less reliant on memorizing facts. School libraries have been largely replaced or augmented by online databases. If AI can do the same work as a human, Mintz argues, then it’s pointless for humans to be competing with that. Humans should be focusing on their unique abilities, such as finding the best questions to ask AIs, learning skills that aren’t in the AI’s training data, and turning the advanced observations of AI into real actions. These require skills like exploration, curiosity, and leadership – things that humans excel at, but AI, not so much. So how can these Large Language Models practically assist teachers like Stephen Mintz in the classroom? When asked this question, GPT-4 generated a few suggestions. Firstly, the AI could create personalized tests or lesson plans for pupils, taking into account their learning goals, strengths and weaknesses, and overall progress, then give thorough and immediate feedback as needed. It could also facilitate group collaboration, by creating games or scenarios to make students work together to solve problems, all while providing support and structure. Finally, AI could act as a facilitator for debates and discussions, providing facts, prompts, and counterarguments as needed, at a much faster and more accurate rate than any human could. This could give teachers the freedom to sit back and observe and assess students’ performance. However, the successful future of AI in education isn’t guaranteed. When prompted, GPT-4 offers optimistic and pessimistic predictions. Optimistically, in the next fifty years AI becomes readily available, and gives teachers more opportunities to engage and inspire their students. However, GPT-4’s pessimistic prediction sees this technology limited by cost and privacy concerns, meaning that the advantages are only given to a privileged few, creating further inequity in the education system. These scenarios may have been generated by AI, but it is up to humans to decide which one comes to light.

---

## CHAPTER 2 OF 5: AI and Creativity

Imagine an Artificial Intelligence that could quickly and faithfully create an original song – music, lyrics, the whole lot – in the style of John Lennon. It may not be his best work, but it certainly isn’t bad, and anyone familiar with the source material might even nod and say: “Yup, he could have written that.” The immediate reaction of many musicians would be fear: their work just became a lot less necessary. But what if you were John Lennon and had that technology? You could ask it to generate a song, or several songs about whatever you want, then pick and choose the best bits to adapt as necessary and make something even better. All straight after that first spark of inspiration. This doesn’t just apply to music. Video game developers could generate branching narratives or dialogues, to be reviewed and edited as necessary. Architects could quickly turn sketches into realistic models to work with. The list goes on. When asked about the creative future of humanity, GPT-4 says it’s curious but cautious. There are legitimate concerns that artists will face, such as loss of artistic or creative identity as AI influences the direction of their work, or saturation of the marketplace as it becomes easier for anyone to create high-quality art. This is to say nothing of ethical or legal issues as the true origin of works is brought into question. But GPT-4 also offers several possible solutions to mitigate these negative consequences. Standards and guidelines regarding the cultural use of AI need to be developed and enforced to ensure that consumers aren’t being deceived. This could involve making sure that people are transparent and accountable, and not abusing or misusing the technology. By fostering a culture of awareness and media literacy, more people would be aware of the potential problems of AI, and take that into account when creating. There’ll always be a place for human creators. Their work could be acknowledged and encouraged, with individuals given incentives and opportunities to pursue their artistic aspirations. But all that leaves the question of who owns AI’s artistic productions. Luckily, OpenAI doesn’t claim ownership of anything created with its software. If GPT-4 isn’t used to harm or infringe on the rights of others, or generate inappropriate content, it can be used however an artist sees fit. Just like painters’ careers were disrupted by the invention of photography in the nineteenth century, there are going to be some changes to the artistic playing field. If we remain cautious but curious, these changes could be very exciting.

---

## CHAPTER 3 OF 5: AI and Justice

Right now in the US there are more African American men in the prison system than there were slaves living in 1850. The consequences of past injustices are still a constant part of life for many people, and while the causes and solutions are complex and disputed, Artificial Intelligences like GPT-4 may be able to help. First off, this needs to be approached cautiously. There are already legitimate problems regarding human biases being picked up by AI algorithms, which is a serious concern. With that in mind, the best way to improve the justice system is by using AI to empower individuals, rather than creating faceless, automated procedures. What could this look like? Take police body-cameras, for example. On the one hand, they create greater transparency and trust. However, they can also be an invasion of privacy, and a form of surveillance for minority communities. AI can assist by automatically identifying and removing personal information, or perhaps detecting whether an officer is abusing their power or using excessive force. Legal services can also be helped by AI. GPT-4 excels at quickly creating texts in specific formats and styles, including that of court briefings and other legal language. This could help financially disadvantaged defendants keep up with the speed and quality of richer lawyers – meaning that the quality of your legal service doesn’t depend on the size of your wallet. GPT-4 is also great at quickly sorting through large amounts of information. This could help those who are unfamiliar with the law, or simply make the lives of grunt-level lawyers and paralegals easier by removing the need to repeatedly read through mind-numbing contracts and legal documents. Finally, AI could also help prevent and detect white-collar crime. When asked, GPT-4 is confident that AI could have caught Bernie Madoff – fraudster and orchestrator of the largest Ponzi scheme in history – faster than humans by analyzing patterns and data at a level invisible to the eye. AI is also less likely to be manipulated or distracted than human investigators, making it perfect for tracking suspicious or illegal activity. This is not to say that AI is going to make the legal system perfect – the human element will always lead to imperfections. However, it’s still something to strive for, and AI is going to go a long way toward bringing us closer to that ideal future.

---

## CHAPTER 4 OF 5: AI and Journalism

By the year 2025, it is predicted that the world will have produced about 175 trillion gigabytes of data. If this number seems mind-bogglingly large, that’s because it is. With that much data you could stream Netflix for over eighty-five million years. Clearly, most of this information will not be newsworthy. So how do we find the data that is? This is where AI collides with the critical world of journalism. It’s important to ensure that the concept “Truth” has a future, and isn’t lost in this overwhelming mass of information. There are three aspects to this, all of which can be greatly helped by AI. First, the institutions providing this truth need to work more quickly. Second, they have to engage with their audiences – the consumers of the news and information – in a productive way. Finally, this truth can’t get lost among all the other nonsense out there. What would this look like with GPT-4? Imagine the AI sorting through hundreds of thousands of records or social media posts, instantly transcribing interviews, and quickly generating headlines and articles in any style or format. If this is a bit concerning to you, that’s okay. There are a few things to consider. GPT-4 is known to occasionally, with absolute confidence, assert something that is completely false. Not ideal for an industry based around truth. This is why human journalists will always be of utmost importance – to review, assess, and fact-check anything produced by AI. But the speed at which these journalists can get accurate news out to the public will be drastically increased. What about consumers of news? Asking GPT-4 to find and summarize stories on different topics is a very different experience from simply Googling for information. You can ask for more details on a specific point, have things reworded, or any other level of clarification and customization – much more useful than a list of links to filter through yourself. If people have more control over how they get their news, they will want more of it. The flipside is that it is also easier for malicious parties to quickly generate and spread misinformation. This is why human critical thinking is more important than ever. Imagine reading an article from Fox News or The New York Times, and being able to click a “fact check” button next to the “like” or “share” buttons at the bottom. AI is a tool. It will be up to us to use it responsibly and critically.

---

## CHAPTER 5 OF 5: When AI Hallucinates

Here are some criticisms that have been made by respected journalists and researchers: “It’s a flawed and irresponsible research tool.” “You should always double check everything at its source.” “It’s unleashing misinformation to the masses.” Sounds like they’re being quite harsh about GPT-4, right? Actually, these are all things that were said about the now beloved and trusted Wikipedia. And before that, these claims were made about the internet itself. This isn’t to excuse GPT-4’s mistakes and shortcomings, but it just goes to show that these fears are nothing new. There are four main types of mistakes that Large Language Models make, often described as “hallucinations.” The first is when the AI generates text that just makes no sense at all. This is the least problematic, because it’s easiest to identify. Sometimes the AI gives an answer that is convincing, but wrong. This is a bit more of a problem, because LLMs like GPT-4 are trained to give answers with confidence and authority, which makes the error hard to spot, and easy to believe. Another hallucination is when the AI claims to possess properties that it doesn’t have, or do things that it’s never been trained for – something like feeling love, or cooking a meal. Finally, hallucinations can be purposeful and dangerous. These occur when the model is prompted with false information, with the intention of doing harm. While this is more the responsibility of the human user, it’s still something to be wary of. These hallucinations should be acknowledged and corrected in whatever way possible, but it’s important to keep things in perspective. There’s a lot of value in “good enough” knowledge – we all accept that there are mistakes and imperfections in Wikipedia, but there are still billions of page views every day. Every technological leap comes with its risks. The invention of fire and the wheel changed the path of humanity, but we still need laws about where you can have barbecues and how fast you can drive. It comes down to regulation. As the full scope and implications of software like GPT-4 become widely known, the necessary restrictions and guidelines will come. The more people using a product, the higher the visibility of errors, and the more incentive companies have to keep it safe and bug-free. Judging from the speed at which things are changing and improving, these hallucinations will become increasingly negligible – and, with the right guidance, AI like GPT-4 will elevate us to an exciting and optimistic future.

---

## CONCLUSION: Final Summary

Humanity is at a crossroads. Large Language Models like GPT-4 are going to change the world, and it is up to us to decide what this will look like. Yes, there are dangers – but without risk there can never be any progress. If developed, distributed, and regulated carefully, AI can become a versatile and productive tool that could elevate the capabilities of humanity. Just like it’s hard to imagine a world without smartphones, there will come a time when society will feel like it’s built around this new technology. But we must never let it replace us. As AI becomes more widespread and autonomous, we must start expecting more from ourselves. We must never forget the values, the creativity, and the judgment that make us human, but instead use AI to augment and encourage these essential traits. There’s a new and exciting road ahead of us. Let’s walk carefully, but confidently, forward.
