# Superinteligência

**Autor:** Nick Bostrom
**Descrição:** undefined
**Duração:** undefined min | **Avaliação:** [object Object]/5

---

## INTRODUÇÃO: Qual é o ganho para mim? Saiba como as máquinas podem superar a humanidade.

Quantos filmes, desenhos animados e séries de ficção científica você já viu com alguma espécie de máquina superinteligente? Provavelmente muitos. Em alguns filmes, como Terminator, elas vêm conquistar o mundo; em outros, nos ajudam; e em alguns, como Wall-E, são simplesmente adoráveis. É claro que esses robôs são fictícios, mas sempre serão? O futuro trará uma IA superinteligente? Se isso acontecer, como será e quando surgirá? Em Superinteligência, aprendemos sobre a jornada da IA até agora – para onde podemos estar indo; as questões morais e de segurança que precisamos resolver; e as melhores maneiras de alcançar o objetivo de criar uma máquina que ultrapasse todas as outras. Nestes resumos, você descobrirá por que a maioria dos cientistas acredita que atingiremos superinteligência até 2105; a diferença entre Inteligência Artificial e Emulação de Cérebro Completo; e como uma conferência em 1956 em Dartmouth desempenhou um papel central na criação dessa tecnologia.

---

## CAPÍTULO 1 DE 8: A história mostra que a superinteligência – uma tecnologia mais inteligente que qualquer ser humano – está se aproximando rapidamente.

O que nos diferencia fundamentalmente dos animais? Bem, a principal diferença entre seres humanos e animais é nossa capacidade de pensamento abstrato aliada à habilidade de comunicar e acumular informações. Em essência, nossa inteligência superior nos levou ao topo. Então, o que significaria para o mundo o surgimento de uma nova espécie intelectualmente superior aos humanos? Primeiro, precisamos revisar um pouco de história. Por exemplo, você sabia que o ritmo das grandes revoluções tecnológicas vem aumentando ao longo do tempo? Por exemplo, melhorando no ritmo de caracol de alguns milhares de anos atrás, a tecnologia humana precisaria de um milhão de anos para se tornar economicamente produtiva o suficiente para sustentar as vidas de um milhão de pessoas adicionais. Esse número caiu para dois séculos durante a Revolução Agrícola em 5.000 a.C. E na era pós-Revolução Industrial encolheu para apenas 90 minutos. Um avanço tecnológico como o advento de máquinas superinteligentes significaria mudança radical para o mundo como conhecemos. Mas onde a tecnologia está no presente? Já conseguimos criar máquinas que têm a capacidade de aprender e raciocinar usando informações inseridas por humanos. Considere, por exemplo, os filtros automáticos de spam que mantêm nossas caixas de entrada livres de emails em massa irritantes e salvam mensagens importantes. Porém, isso está longe do tipo de "inteligência geral" que os humanos possuem e que é o objetivo da pesquisa de IA há décadas. E quando se trata de construir uma máquina superinteligente que pode aprender e agir sem a orientação de um humano, ainda pode estar décadas distante. Mas os avanços no campo estão acontecendo rapidamente, então pode chegar antes do que pensamos. Tal máquina teria muito poder sobre nossas vidas. Sua inteligência poderia ser perigosa, já que seria muito inteligente para que a desativássemos em caso de emergência.

---

## CAPÍTULO 2 DE 8: O histórico de inteligência de máquina nos últimos cinquenta anos teve altos e baixos.

Desde a invenção dos computadores em 1940, cientistas trabalham para construir uma máquina que possa pensar. Qual progresso foi feito? Um grande avanço em Inteligência Artificial (ou IA) são máquinas criadas pelo homem que imitam nossa própria inteligência. A história começa com o Projeto de Verão de Dartmouth em 1956, que se esforçou para construir máquinas inteligentes que pudessem fazer o que humanos fazem. Algumas máquinas poderiam resolver problemas de cálculo, enquanto outras poderiam escrever música e até dirigir carros. Mas havia um obstáculo: os inventores perceberam que quanto mais complexa a tarefa, mais informações a IA precisava processar. Não havia hardware disponível para lidar com funções tão difíceis. Por meados dos anos 1970, o interesse em IA tinha desaparecido. Mas no início dos anos 1980, o Japão desenvolveu sistemas especialistas – programas baseados em regras que ajudavam os tomadores de decisão gerando inferências com base em dados. Porém, essa tecnologia também encontrou um problema: os enormes bancos de informações necessários se mostraram difíceis de manter, e o interesse caiu novamente. Os anos 1990 testemunharam uma nova tendência: máquinas que imitavam a biologia humana usando tecnologia para copiar nossas estruturas neurais e genéticas. Esse processo nos traz até o presente. Hoje, a IA está presente em tudo, desde robôs que realizam cirurgias até smartphones e uma simples busca no Google. A tecnologia melhorou ao ponto de conseguir vencer os melhores jogadores humanos em xadrez, Scrabble e Jeopardy! Mas nem mesmo nossa tecnologia moderna está isenta de problemas: essas IAs podem ser programadas apenas para um jogo e não há IA capaz de dominar qualquer jogo. Porém, nossos filhos podem ver algo muito mais avançado – o advento da superinteligência (ou SI). De fato, de acordo com uma pesquisa de especialistas internacionais da Segunda Conferência sobre Inteligência Artificial Geral na Universidade de Memphis, em 2009, a maioria dos especialistas acredita que máquinas tão inteligentes quanto humanos existirão até 2075 e que superinteligência existirá em outros 30 anos.

---

## CAPÍTULO 3 DE 8: Superinteligência provavelmente emergirá de duas maneiras diferentes.

É claro que imitar inteligência humana é uma forma eficaz de construir tecnologia, mas a imitação vem em muitas formas. Então, enquanto alguns cientistas favorecem o design sintético de uma máquina que simule humanos (através de IA, por exemplo), outros defendem uma imitação exata da biologia humana, uma estratégia que poderia ser alcançada com técnicas como Emulação de Cérebro Completo (ou ECC). Então, quais são as diferenças entre as duas? A IA imita a forma como os humanos aprendem e pensam calculando probabilidades. Basicamente, a IA usa lógica para encontrar maneiras mais simples de imitar as habilidades complexas dos humanos. Por exemplo, uma IA programada para jogar xadrez escolhe o movimento ótimo primeiro determinando todos os movimentos possíveis e depois escolhendo o com maior probabilidade de vencer o jogo. Mas essa estratégia depende de um banco de dados que contém todos os movimentos de xadrez possíveis. Portanto, uma IA que faz mais do que apenas jogar xadrez precisaria acessar e processar enormes quantidades de informações do mundo real. O problema é que os computadores atuais simplesmente não conseguem processar a quantidade necessária de dados rápido o suficiente. Mas existem maneiras de contornar isso? Uma possível solução é construir o que o cientista da computação Alan Turing chamou de "máquina criança" – um computador que vem com informações básicas e é projetado para aprender com a experiência. Outra opção é a ECC, que funciona replicando toda a estrutura neural do cérebro humano para imitar sua função. Uma vantagem que esse método tem sobre a IA é que não requer compreensão completa dos processos por trás do cérebro humano – apenas a capacidade de duplicar suas partes e as conexões entre elas. Por exemplo, um cientista poderia pegar um cérebro estabilizado de um cadáver, digitalizá-lo completamente e depois traduzir essa informação em código. Mas teremos que esperar. A tecnologia necessária para esse processo – varreduras cerebrais de alta precisão, por exemplo – provavelmente não será desenvolvida tão cedo. Mas, um dia, será.

---

## CAPÍTULO 4 DE 8: Superinteligência emergirá rapidamente via dominância estratégica ou como resultado de esforços colaborativos prolongados.

A maioria das grandes descobertas da humanidade foi alcançada por um único cientista que chegou a um objetivo antes dos outros ou através de enormes colaborações internacionais. Então, o que cada rota significaria para o desenvolvimento de SI? Bem, se um único grupo de cientistas encontrasse rapidamente soluções para os problemas que impedem IA e ECC, muito provavelmente seus resultados produziriam uma única máquina superinteligente. Isso ocorre porque a natureza competitiva do campo poderia forçar esse grupo a trabalhar em segredo. Considere o Projeto Manhattan, o grupo que desenvolveu a bomba atômica. As atividades do grupo foram mantidas em sigilo porque o governo dos EUA temia que a URSS usasse sua pesquisa para construir armas nucleares próprias. Se SI se desenvolvesse assim, a primeira máquina superinteligente teria uma vantagem estratégica sobre todas as outras. O perigo é que uma única SI poderia cair em mãos nefastas e ser usada como arma de destruição em massa. Ou se uma máquina funcionasse mal e tentasse fazer algo terrível – matar todos os humanos, digamos – não teríamos nem a inteligência nem as ferramentas necessárias para nos defender. Porém, se múltiplos grupos de cientistas colaborassem, compartilhando avanços em tecnologia, a humanidade construiria gradualmente a SI. Um esforço em equipe como esse poderia envolver muitos cientistas verificando cada etapa do processo, garantindo que as melhores escolhas fossem feitas. Um bom precedente para essa colaboração é o Projeto Genoma Humano, um esforço que reuniu cientistas de múltiplos países para mapear o DNA humano. Outra técnica eficaz seria supervisão pública – instituindo regulamentações de segurança governamentais e estipulações de financiamento que desestimulassem cientistas a trabalhar independentemente. Então, enquanto o desenvolvimento rápido de uma única SI ainda poderia ocorrer durante esse processo colaborativo lento, um esforço aberto em equipe seria mais provável de ter protocolos de segurança em vigor.

---

## CAPÍTULO 5 DE 8: Podemos prevenir catástrofes não intencionais programando superinteligência para aprender valores humanos.

Você provavelmente já ouviu isso um milhão de vezes, mas há sabedoria em ser cuidadoso com o que se deseja. Enquanto podemos estar lutando para obter superinteligência, como garantir que a tecnologia não compreenda mal seu propósito e cause devastação indizível? A chave para esse problema está em programar a motivação para a SI realizar seus vários objetivos dados por humanos. Digamos que projetássemos uma SI para fazer clipes de papel; parece inócuo, mas o que impediria a máquina de levar sua tarefa ao extremo e absorver todos os recursos do mundo para fabricar uma montanha de suprimentos de escritório? Isso é complicado, porque enquanto a IA é motivada apenas a alcançar o objetivo para o qual foi programada, uma SI provavelmente iria além de seus objetivos programados de maneiras que nossas mentes inferiores não conseguem prever. Mas existem soluções para esse problema. Por exemplo, superinteligência, seja IA ou ECC, pode ser programada para aprender os valores de um humano por conta própria. Por exemplo, uma SI poderia ser ensinada a determinar se uma ação está alinhada com um valor humano fundamental. Dessa forma, poderíamos programar a SI para fazer coisas como "minimizar sofrimento desnecessário" ou "maximizar retornos." Depois, antes de agir, a máquina calcularia se uma ação proposta está alinhada com esse objetivo. Com experiência, a IA desenvolveria um senso de quais ações estão em conformidade e quais não estão. Mas existe outra opção. Poderíamos também programar uma IA para inferir nossas intenções com base nos valores majoritários de seres humanos. Assim: A IA observaria comportamento humano e determinaria padrões normativos para desejos humanos. A máquina seria essencialmente programada para programar a si mesma. Por exemplo, enquanto cada cultura tem sua própria tradição culinária, todos concordam que alimentos venenosos não devem ser comidos. Aprendendo constantemente através da observação, a SI poderia se auto-corrigir mudando seus padrões para corresponder a mudanças no mundo ao longo do tempo.

---

## CAPÍTULO 6 DE 8: Máquinas inteligentes provavelmente substituirão toda a força de trabalho humana.

Mas chega de decimação e destruição total. Antes de entrar em pânico sobre o iminente apocalipse liderado por máquinas, vamos analisar como a tecnologia de inteligência geral pode ser desenvolvida e utilizada de forma produtiva. É provável que a crescente disponibilidade e o custo decrescente da tecnologia levem à produção em massa barata de máquinas capazes de fazer trabalhos que atualmente exigem as mãos e a mente de um humano. Isso significa que as máquinas não apenas substituirão toda a força de trabalho humana, mas também serão facilmente substituíveis. Por exemplo, se um trabalhador ECC precisa de uma pausa, assim como um humano real, ele pode simplesmente ser substituído por uma unidade nova e nenhum tempo produtivo precisa ser sacrificado. De fato, seria fácil fazer isso programando um modelo ECC que pensa que acabou de voltar de férias. Este modelo poderia então ser usado para fazer cópias infinitas de novos trabalhadores. Mas claramente isso constitui escravidão mecânica e levanta questões morais importantes. Por exemplo, se uma máquina se tornasse consciente de que morreria no final do dia, poderíamos simplesmente programá-la para aceitar a morte. Mas isso é ético? Essas máquinas artificiais deveriam ser tratadas como seres sencientes ou ferramentas inanimadas? O trabalho não é a única coisa que máquinas SI poderiam assumir; elas também poderiam estar encarregadas de várias tarefas mundanas em nossas vidas pessoais. Conforme as mentes dessas máquinas se aproximam cada vez mais de se assemelharem às de seres humanos, poderíamos usá-las para otimizar nossas vidas; por exemplo, poderíamos projetar um programa digital que articule verbalmente nossos pensamentos ou que alcance nossos objetivos pessoais melhor do que poderíamos sozinhos. O resultado de tais avanços significaria uma existência humana largamente automatizada, de baixo risco, desprovida de aventura e, francamente, muito perfeita. E onde isso nos deixaria? Como nos ocuparíamos em um futuro assim?

---

## CAPÍTULO 7 DE 8: No futuro superinteligente, o humano médio será empobrecido ou dependerá de investimentos; os ricos estarão comprando novos luxos.

É claro que uma força de trabalho inteiramente robótica transformaria completamente a economia, bem como nossos estilos de vida e desejos; conforme o trabalho de máquinas se torna a nova norma mais barata, o salário dos trabalhadores cairá tão baixo que nenhum humano conseguirá viver com um contracheque. Também, os poucos empregadores da força de trabalho mecânica acumulariam muito dinheiro. Mas isso nos traz de volta a um ponto anterior, porque para onde esse dinheiro vai também depende se SI foi projetada por um único grupo exclusivo ou é resultado de um processo colaborativo lento. Se o primeiro se revelar verdadeiro, a maioria das pessoas ficaria com poucas opções para gerar renda, provavelmente alugando moradias para outros humanos ou dependendo de poupança e pensões. E as pessoas que não têm propriedade ou poupança? Ficariam desamparadas. Suas únicas opções seriam usar seu dinheiro restante para se transferirem para uma forma de vida digital, se tal tecnologia existir, ou depender da caridade do hiperricos. E os ricos? Perderão o interesse no que hoje consideramos luxos altamente desejáveis. Isso ocorre porque com máquinas fazendo todo o trabalho, qualquer coisa feita ou oferecida por um humano se tornaria uma raridade altamente valorizada, assim como produtos artesanais são em nosso tempo. Enquanto hoje pode ser vinho ou queijo, no futuro poderia ser algo tão simples quanto um chaveiro feito à mão. Mas o novo modo de produção também possibilitaria uma variedade inimaginável de produtos tecnológicos – talvez até a capacidade de viver para sempre ou recuperar a juventude. Então, em vez de comprar iates e ilhas particulares, os ricos poderiam usar seu dinheiro para se transferirem para cérebros digitais ou corpos humanoides virtualmente indestrutíveis. Porém, esse cenário assume que os robôs trabalhadores superinteligentes não se rebelarão e tentarão destruir a sociedade humana. Portanto, independentemente de qual rota seguirmos com SI, a segurança sempre será fundamental.

---

## CAPÍTULO 8 DE 8: A segurança deve ser uma prioridade máxima antes da superinteligência ser desenvolvida.

É claro que o desenvolvimento de SI vem com uma variedade de questões de segurança e, no pior cenário possível, poderia levar à destruição da humanidade. Enquanto podemos tomar algumas precauções considerando a motivação para a SI que construímos, apenas isso não será suficiente. Então, o que será? Considerar cada cenário potencial antes de trazer uma força hiper-poderosa como SI para o mundo. Por exemplo, imagine que alguns pardais adotassem um filhote de coruja. Ter uma coruja leal por perto poderia ser altamente vantajoso; o pássaro mais poderoso poderia guardar os filhotes, procurar alimento e fazer qualquer número de outras tarefas. Mas esses grandes benefícios também vêm com grande risco: a coruja poderia perceber que é uma coruja e comer todos os pardais. Portanto, a abordagem lógica seria os pardais projetarem um plano excelente para como ensinar a coruja a amar pardais, enquanto também considerassem todos os possíveis resultados nos quais a coruja poderia se tornar uma força negativa. Então, como podemos ensinar nosso bebê coruja robótico e superinteligente a amar humanos? Como já sabemos, podemos tornar a segurança uma prioridade através de uma colaboração internacional de longo prazo. Mas por que a corrida competitiva para projetar a primeira SI seria uma ameaça à segurança? Porque cientistas abririam mão da segurança para acelerar seu processo e não compartilhariam seu trabalho com outros. Isso significa que se um projeto de SI corresse terrivelmente errado e ameaçasse a humanidade com extinção, muito poucas pessoas compreenderiam o design da máquina bem o suficiente para detê-lo. Por outro lado, se governos, instituições e grupos de pesquisa se unissem, poderiam construir lentamente uma SI segura e altamente benéfica. Isso ocorre porque grupos poderiam compartilhar suas ideias sobre medidas de segurança e fornecer supervisão minuciosa para cada fase do projeto. Não apenas isso, mas um projeto de superinteligência internacional promoveria paz através de seus benefícios universais. Considere apenas a Estação Espacial Internacional, um esforço que ajudou a estabilizar as relações entre EUA e URSS.

---

## CONCLUSÃO: Resumo final

A mensagem-chave deste livro: Inventar uma máquina superinteligente capaz de coisas muito além da capacidade de um humano é tanto uma perspectiva tentadora quanto um caminho precário. Para garantir que essa tecnologia se desenvolva de forma segura e responsável, precisamos priorizar a segurança sobre o avanço tecnológico descontrolado. O destino de nossa espécie depende disso. Leitura recomendada: Out of Control de Kevin Kelly. Embora escrito sob a perspectiva de 1994, estes resumos pintam uma imagem surpreendentemente atual e ainda futurista de como desenvolvimentos tecnológicos como a internet e inteligência artificial poderiam afetar a sociedade e a humanidade. Tem feedback? Adoraríamos ouvir o que você pensa sobre nosso conteúdo! Basta enviar um email para remember@blinkist.com com o título deste livro como assunto e compartilhe seus pensamentos!
