# O Problema do Alinhamento

**Autor:** Brian Christian
**Descrição:** Aprendizado de Máquina e Valores Humanos
**Duração:** 7 min | **Classificação:** 2.9/5

---

## INTRODUÇÃO: Qual é o benefício para mim? Aprenda como programas de IA nos refletem os piores aspectos da humanidade.

Converse com qualquer pessoa e ela terá uma opinião sobre IA. "Vai melhorar o trabalho." "Vai tirar nossos empregos." "Vai trazer paz mundial." "Vai destruir o mundo." Ainda há muito que não sabemos sobre o que a IA evoluirá, quem a usará e como ela será usada. O que sabemos é que ela está se desenvolvendo em ritmo acelerado e sendo lançada no mundo sem um nível decente de testes. E nesse processo, ela nos ensina algo sobre nós mesmos. Um dos comportamentos chocantes frequentemente exibidos pela IA é seu viés e racismo. Para entender por que isso acontece, temos que viajar até o século dezenove, quando Frederick Douglass se tornou a pessoa mais fotografada do mundo. Neste breve Blink, viajaremos até o início dos anos 2010, quando uma jovem desenvolvedora descobriu que seu robô de IA se recusava a reconhecer seu rosto a menos que ela usasse uma máscara branca. Por fim, falaremos sobre as esperanças e advertências que essas histórias têm para nós.

---

## CAPÍTULO 1 DE 2: A IA costuma ser racista

Em 2015, uma jovem desenvolvedora web chamada Jacky Alciné recebeu uma notificação de que seu amigo havia compartilhado uma foto com ele no Google Fotos. Quando ele abriu o aplicativo, viu que uma nova interface de usuário (ou UI) havia sido instalada. Agora, a IA do Google estava agrupando as fotos em categorias como "formatura" ou "praia". Alciné viu uma selfie com ele e seu melhor amigo, ambos negros. A legenda sob a selfie lia "gorilas". Quando ele abriu a pasta, viu dezenas de imagens dele e seu amigo, e nada mais. Ele imediatamente foi ao Twitter e denunciou o Google Fotos. Recebeu uma resposta em duas horas e o Google começou a trabalhar na resolução do problema. A partir de 2023, a melhor solução deles foi remover a categoria de gorilas de sua UI. Eles ainda não encontraram uma maneira de fazer seu programa identificar gorilas sem classificar incorretamente pessoas negras. Para entender como isso aconteceu, temos que voltar à pessoa mais fotografada do século dezenove – Frederick Douglass. O famoso abolicionista ficou feliz quando a tecnologia da fotografia começou a ser acessível ao público. Até então, as únicas representações de pessoas negras estavam em desenhos feitos por pessoas brancas. Esses desenhos exageravam bastante as características das pessoas negras, fazendo-as parecerem mais animais do que humanos. Douglass acreditava que a fotografia daria às pessoas negras uma representação melhor. Ele ficou feliz em posar para fotos por essa razão e encorajou pessoas negras a se tornarem fotógrafas. Este foi um bom começo, mas o problema não era apenas representação. O problema estava na própria tecnologia. Essencialmente, as câmeras em si eram racistas. Isso ocorreu porque o filme foi criado com um revestimento químico especial, e esse revestimento havia sido criado com base em como a pessoa ou objeto sendo filmado ou fotografado parecia sob várias luzes. Para obter boas imagens em filme, Hollywood usava uma mulher branca (a primeira se chamava Shirley) para posar para a câmera e otimizar o filme. O revestimento do filme foi desenvolvido para fazer Shirley parecer seu melhor. Este processo ignorou completamente pessoas com tons de pele mais escuros. Felizmente, esse problema foi resolvido pela Kodak nos anos 70 – mas não por causa do movimento dos direitos civis; na verdade, foi porque empresas de móveis e doces queriam melhores representações fotográficas de seus produtos na mídia. Então a Kodak começou a otimizar o filme para incluir cores mais escuras. Um efeito colateral feliz (para a Kodak) foi que abriu uma entrada para um demográfico totalmente novo. Do lado negativo, décadas de fotografia e filme perderam representações precisas e claras de qualquer pessoa que não fosse branca. Avançando para a época de Alciné, vemos instâncias de IA não reconhecendo pessoas negras como humanas – ou não reconhecendo seus rostos. Agora que entendemos como o racismo está entrelaçado com a tecnologia, na próxima seção falaremos sobre por que a IA de hoje não consegue superar esse problema – e o que está sendo feito a respeito.

---

## CAPÍTULO 2 DE 2: Como criar IA inclusiva

No início dos anos 2010, uma estudante de pós-graduação chamada Joy Buolamwini estava trabalhando em um projeto de robótica. O robô com o qual ela estava trabalhando foi treinado em reconhecimento facial, e ela estava tentando ensiná-lo a jogar pique-esconde. O único problema era que ele não reconhecia seu rosto. Para completar o projeto, ela teve que pedir a um amigo para estar no lugar dela. Alguns anos depois, ela estava visitando Hong Kong e recebendo um tour e demonstração de um robô social. Novamente, o robô reconheceu todos no seu grupo de tour exceto por ela. Como se viu, o robô havia sido programado no mesmo código de fonte aberta que seu robô de pique-esconde. Eventualmente, Buolamwini identificou o problema. O programa original foi treinado em fotos de um conjunto de dados chamado Faces in the Wild. Quando ela investigou, descobriu que essas imagens foram altamente enviesadas em favor de homens brancos. Menos de cinco por cento eram imagens de mulheres de pele escura. Não é de se estranhar que os robôs de Buolamwini não reconhecessem seu rosto. Ela entrou em contato com várias empresas de tecnologia para compartilhar o que havia descoberto. A única que respondeu positivamente foi a IBM. Eles verificaram seus resultados e depois começaram a trabalhar na melhoria dos conjuntos de dados e retreinamento do algoritmo. Em poucas semanas, eles reduziram erros na identificação dos rostos de mulheres negras em dez vezes. Esta história é apenas o começo. Ao considerar se a IA é a onda do futuro ou nos destruirá, temos que olhar mais profundamente para o passado do que estamos fazendo atualmente. Essencialmente, a IA é apenas tão boa quanto o treinamento que recebe. Quando vemos novos programas de IA de código aberto se comportando mal, é provável que seja porque estão treinando na internet, que é criada por pessoas – e as pessoas nem sempre exibem o comportamento mais desejável. O aviso aqui é que os desenvolvedores cometeram grandes erros por não entender a natureza da história e humanidade que informam nossa tecnologia, e apressar-se a colocar novas tecnologias no mercado representa uma ameaça ao nosso futuro.

---

## CONCLUSÃO: Resumo final

Não podemos desenvolver IA independentemente da história humana. Esses programas são apenas tão bons quanto os conjuntos de dados em que treinam. O histórico da América de representação inadequada ou exclusão de pessoas negras da fotografia e do cinema abriu caminho para conjuntos de dados que são fortemente enviesados em favor de homens brancos. A única maneira de corrigir esse problema específico é alterar os conjuntos de dados. No entanto, a lição maior é que lançar novas tecnologias de IA sem testes e perspectivas diversas é imprudente e potencialmente prejudicial para a humanidade.
